import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split

# Configuración para visualizaciones y pandas
sns.set_style("whitegrid")
pd.options.display.max_columns = None
plt.rcParams['figure.figsize'] = [10, 6] # Tamaño de figura estándar

# --- 1. Cargar el Dataset ---
# Asegúrese de que este nombre de archivo coincida con el CSV que subió
file_path = "Sleep_health_and_lifestyle_dataset.csv" 
df = pd.read_csv(file_path)

print("=========================================================")
print("  ANÁLISIS DE PATRONES DE SUEÑO Y ESTILOS DE VIDA")
print("=========================================================")

# --- 2. Exploración de Datos y Transformaciones Iniciales ---

print("\n--- 2. Exploración de Datos (Análisis, Limpieza, Transformaciones) ---")
print(f"Dimensiones Iniciales: {df.shape[0]} filas, {df.shape[1]} columnas")
print("Tipos de Datos y Valores Nulos:")
df.info()

# 2.1. Tratamiento de Duplicados
num_duplicados = df.duplicated().sum()
if num_duplicados > 0:
    df.drop_duplicates(inplace=True)
print(f"\nNúmero de Duplicados Eliminados: {num_duplicados}. Dimensiones Actuales: {df.shape}")

# 2.2. Tratamiento de Valores Vacíos (Verificado con df.info())
print(f"Conteo de Valores Nulos por columna: {df.isnull().sum().sum()} (No hay nulos)")

# 2.3. Transformaciones: Separar 'Blood Pressure' y corregir 'BMI Category'
df[['Systolic_BP', 'Diastolic_BP']] = df['Blood Pressure'].str.split('/', expand=True).astype(float)
df.drop('Blood Pressure', axis=1, inplace=True)
df['BMI Category'] = df['BMI Category'].replace('Normal Weight', 'Normal')
df.drop('Person ID', axis=1, inplace=True)

print("\n--- Explicación de Transformaciones ---")
print("1. **Separación de 'Blood Pressure'**: Descompuesto en 'Systolic_BP' y 'Diastolic_BP' para análisis numérico.")
print("2. **Corrección de 'BMI Category'**: 'Normal Weight' unificado a 'Normal'.")
print("3. **Eliminación de columnas**: Se eliminaron los duplicados y 'Person ID' por ser identificador único.")


# --- 3. Análisis Univariante ---

print("\n\n--- 3. Análisis Univariante y Deducciones ---")
num_cols = df.select_dtypes(include=np.number).columns.tolist()
cat_cols = df.select_dtypes(include='object').columns.tolist()

# 3.1. Distribución de Variables Numéricas
print("\n3.1. Estadísticas Descriptivas:")
print(df[num_cols].describe().T)

# Visualización Numérica
fig_num, axes_num = plt.subplots(4, 2, figsize=(18, 18))
axes_num = axes_num.flatten()
for i, col in enumerate(num_cols):
    sns.histplot(df[col], kde=True, ax=axes_num[i])
    axes_num[i].set_title(f'Distribución de {col}', fontsize=14)
plt.tight_layout()
plt.show()

print("\n--- Deducciones de Variables Numéricas ---")
print(f"**Stress Level**: Concentración en niveles **bajos/moderados (3 y 6)** y picos en niveles **altos (7 y 8)**. El grupo con alto estrés es significativo para el análisis.")
print(f"**Sleep Duration**: Distribución **bimodal**, sugiriendo dos grupos de hábitos de sueño (posiblemente profesionales de baja vs. alta exigencia).")
print(f"**Physical Activity Level**: Muestra picos en niveles bajos y altos de actividad.")


# 3.2. Distribución de Variables Categóricas
print("\n3.2. Distribución de Variables Categóricas:")
# Visualización Categórica
fig_cat, axes_cat = plt.subplots(2, 2, figsize=(18, 12))
axes_cat = axes_cat.flatten()
for i, col in enumerate(cat_cols):
    sns.countplot(y=df[col], ax=axes_cat[i], order=df[col].value_counts().index, palette='viridis')
    axes_cat[i].set_title(f'Conteo de {col}', fontsize=14)
plt.tight_layout()
plt.show()

print("\n--- Deducciones de Variables Categóricas ---")
print(f"**Occupation**: 'Nurse', 'Doctor' y 'Engineer' dominan la muestra, lo que sesga el análisis a estas profesiones.")
print(f"**Sleep Disorder**: Casi el 60% no reporta trastorno. 'Insomnia' y 'Sleep Apnea' son los trastornos principales.")


# --- 4. Filtrado de Outliers por IQR ---

def remove_outliers_iqr(df, columns):
    df_filtered = df.copy()
    initial_rows = len(df_filtered)
    for col in columns:
        Q1 = df_filtered[col].quantile(0.25)
        Q3 = df_filtered[col].quantile(0.75)
        IQR = Q3 - Q1
        # Definición estándar de outlier: 1.5 * IQR
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df_filtered = df_filtered[(df_filtered[col] >= lower_bound) & (df_filtered[col] <= upper_bound)]
    final_rows = len(df_filtered)
    print(f"\nFilas iniciales: {initial_rows}")
    print(f"Filas finales (después de filtrar): {final_rows}")
    print(f"Número de Outliers Extremos eliminados: {initial_rows - final_rows}")
    return df_filtered

numerical_cols_for_iqr = ['Age', 'Sleep Duration', 'Quality of Sleep', 'Physical Activity Level', 
                          'Stress Level', 'Heart Rate', 'Daily Steps', 'Systolic_BP', 'Diastolic_BP']
df_filtered = remove_outliers_iqr(df.copy(), numerical_cols_for_iqr)
df = df_filtered.copy()

print("\n--- Explicación del Filtrado ---")
print("Se utilizó el método del **Rango Intercuartílico (IQR)**. Se eliminaron outliers extremos para **mejorar la robustez del análisis y la precisión de futuros modelos** de clasificación, evitando que valores anómalos distorsionen el entrenamiento.")


# --- 5. Creación de la Variable Objetivo y Eliminación de la Columna Original ---

# Creación de la variable objetivo binaria "Nivel_Estres_Binario"
df['Nivel_Estres_Binario'] = df['Stress Level'].apply(
    lambda x: 'ESTRESADO' if x >= 7 else 'ESTRES MODERADO'
)

# 6. Eliminación de la variable numérica 'Stress Level'
df.drop('Stress Level', axis=1, inplace=True)
print("\n--- 6. Eliminación de la variable numérica 'Stress Level' ---")
print("La variable original ha sido eliminada. La nueva variable objetivo 'Nivel_Estres_Binario' ha sido creada.")


# --- 7. Análisis Bivariante (Variable Objetivo vs. Todas las Variables) ---

print("\n\n--- 7. Análisis Bivariante y Explicaciones ---")
target_col = 'Nivel_Estres_Binario'

# Visualización Categórica vs. Target
cat_cols_biv = [col for col in cat_cols]
fig_biv_cat, axes_biv_cat = plt.subplots(2, 2, figsize=(18, 12))
axes_biv_cat = axes_biv_cat.flatten()
for i, col in enumerate(cat_cols_biv):
    cross_tab = pd.crosstab(df[col], df[target_col], normalize='index') * 100
    cross_tab.plot(kind='bar', stacked=True, ax=axes_biv_cat[i], colormap='plasma')
    axes_biv_cat[i].set_title(f'{col} vs. {target_col}', fontsize=14)
    axes_biv_cat[i].set_ylabel('Proporción (%)')
plt.tight_layout()
plt.show()

# Visualización Numérica vs. Target (Boxplots)
num_cols_biv = [col for col in num_cols if col != 'Stress Level']
fig_biv_num, axes_biv_num = plt.subplots(3, 3, figsize=(18, 18))
axes_biv_num = axes_biv_num.flatten()
for i, col in enumerate(num_cols_biv):
    sns.boxplot(x=target_col, y=col, data=df, ax=axes_biv_num[i], palette='viridis')
    axes_biv_num[i].set_title(f'{col} vs. {target_col}', fontsize=14)
plt.tight_layout()
plt.show()

print("\n--- Explicación de Relaciones Bivariantes ---")
print("1. **Quality of Sleep**: Las personas en el grupo **'ESTRESADO'** tienen una calidad de sueño notablemente **más baja** que el grupo 'ESTRES MODERADO'. Esta es la relación visual más fuerte.")
print("2. **Sleep Duration**: Similar a la calidad, el grupo 'ESTRESADO' tiene duraciones de sueño significativamente **más cortas**.")
print("3. **Occupation**: 'Sales Representative' y 'Software Engineer' tienen una mayor proporción de individuos 'ESTRESADO', sugiriendo un factor de riesgo laboral.")


# --- 8. Matriz de Correlación y Eliminación de Variables ---

# Codificar la variable objetivo para el cálculo de correlación (0: MODERADO, 1: ESTRESADO)
df['Target_Encoded'] = df[target_col].apply(lambda x: 1 if x == 'ESTRESADO' else 0)
correlation_df = df[num_cols_biv + ['Target_Encoded']].copy()
corr_matrix = correlation_df.corr()

plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Matriz de Correlación de Variables Numéricas y Target', fontsize=16)
plt.show()

print("\n--- 8.2. Análisis de Correlación y Decisión de Eliminación ---")
print("Correlaciones con la Variable Objetivo ('Target_Encoded'):")
print(corr_matrix['Target_Encoded'].sort_values(ascending=False).drop('Target_Encoded'))

# Decisión de Eliminación:
# Correlación entre Sleep Duration y Quality of Sleep es muy alta (0.89). 
# Eliminamos Sleep Duration y Diastolic_BP (que tiene menor correlación que Systolic_BP)
df.drop(['Sleep Duration', 'Diastolic_BP', 'Target_Encoded'], axis=1, inplace=True)

print("\n**Variables Eliminadas:**")
print("1. **Sleep Duration**: Eliminada por su altísima correlación (0.89) con 'Quality of Sleep' (multicolinealidad).")
print("2. **Diastolic_BP**: Eliminada porque 'Systolic_BP' tiene mayor relevancia en el análisis de correlación.")


# --- 9. División del Dataset (Train/Test 80/20 Estratificado) y Guardado ---

# Codificación one-hot de las variables categóricas restantes
df_final = pd.get_dummies(df, columns=['Gender', 'Occupation', 'BMI Category', 'Sleep Disorder'], drop_first=True)

# Separar las características (X) y la variable objetivo (y)
X = df_final.drop(target_col, axis=1)
y = df_final[target_col]

# Aplicar la división 80/20 con estratificación
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Recombinar para guardar los archivos CSV
df_train = pd.concat([X_train, y_train], axis=1)
df_test = pd.concat([X_test, y_test], axis=1)

# Guardar los datasets
df_train.to_csv('train.csv', index=False)
df_test.to_csv('test.csv', index=False)

# 9.1. Comprobación de Proporciones
train_proportion = y_train.value_counts(normalize=True) * 100
test_proportion = y_test.value_counts(normalize=True) * 100

print("\n\n--- 9. Comprobación de Estratificación y Guardado ---")
print("Archivos 'train.csv' y 'test.csv' generados y guardados.")
print(f"\nProporción de 'Nivel_Estres_Binario' en TRAIN (80%):\n{train_proportion}")
print(f"\nProporción de 'Nivel_Estres_Binario' en TEST (20%):\n{test_proportion}")
print("\nLa estratificación se mantuvo con éxito.")
